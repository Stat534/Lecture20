---
title: "Lecture 20: Areal Data Model Fitting"
output:
  revealjs::revealjs_presentation:
    theme: white
    center: true
    transition: none
    incremental: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(dplyr)
library(ggplot2)
library(maps)
library(maptools)
library(sf)
library(spdep)
library(readr)
library(CARBayesdata)
library(sp)
library(rgdal)
library(CARBayes)
library(leaflet)
```

# Class Intro

## Intro Questions 
Last Time:

  - Discuss the mechanism for include spatial random effects in for areal data. How is this simulated / how can models account for this?

Today:

- Model Fitting for Areal Data


# `spdep`

## Adjacency Matrix
Using the code below, create an adjacency matrix for Montana. 
Then identify the neighbors for Gallatin county.


```{r, eval = F, echo = T}
MT.counties <- map('county', 'montana', fill = T, plot = F)
map('county', 'montana')
county.ID <- sapply(strsplit(MT.counties$names, ','), 
                    function(x) x[2])
mt.poly <- map2SpatialPolygons(MT.counties, IDs = county.ID)
mt.nb <- poly2nb(mt.poly)
mt.adj.mat <- nb2mat(mt.nb, style = 'B')
```

These functions also work with general shape files.

## Moran's I / Geary's C

Recall:

- Moran's I
$$I =\frac{n \sum_i \sum_j w_{ij} (Y_i - \bar{Y})(Y_j -\bar{Y})}{(\sum_{i\neq j} \;w_{ij})\sum_i(Y_i - \bar{Y})^2}.$$
This is a spatial analogue measuring the lagged autocorrelation.

- Geary's C
$$C=\frac{(n-1)\sum_i \sum_j w_{ij}(Y_i-Y_j)^2}{2(\sum_{i \neq j \; w_{ij}})\sum_i (Y_i - \bar{Y})^2}$$

## Moran's I / Geary's C

- The R package `spdep` contains built in functions for Moran's I and Geary's C.

- `moran.test()` and `geary.test()` both take a numeric vector (response) and a `listw` object created by `nb2listw` as arguments.


## Moran's I / Geary's C


Using the Tester - Rosendale election results, compute and interpret Moran's I and Geary's C with the proportion voting for Tester.



```{r, echo = T, eval = F}
Tester <- read_csv('Tester_Results.csv')
Tester <- Tester %>% 
  mutate(Tester_Prop = TESTER / (TESTER + ROSENDALE + BRECKENRIDGE))

#drop Yellowstone National Park
mt.poly.noYNP <- mt.poly[1:56,]
mt.nb.noYNP <- poly2nb(mt.poly.noYNP)
mt.listw <- nb2listw(mt.nb.noYNP, style = 'W')

```

## SAR / CAR
The `spdep` package also contains the functionality to fit SAR / CAR models. 

Follow the include tutorial code and answer these four questions.

1. Summarize the data set, note Z is a standardized (standard normal) response for PROPCAS
2. What is nyadjmat
3. Summarize the results from SAR
4. Choose a model between lm0, SAR, and CAR

```{r, echo = F, eval = F}
# 1. summarize the data set, note Z is a standardized (standard normal) response for PROPCAS
nydata <- st_read(system.file("shapes/NY8_bna_utm18.gpkg", package="spData")[1], quiet=TRUE)

lm0 <- lm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata)
summary(lm0)
AIC(lm0)

# 2. What is nyadjmat
suppressMessages(nyadjmat <- as.matrix(foreign::read.dbf(system.file(
  "misc/nyadjwts.dbf", package="spData")[1])[-1]))
suppressMessages(ID <- as.character(names(foreign::read.dbf(system.file(
  "misc/nyadjwts.dbf", package="spData")[1]))[-1]))



nyadjlw <- mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY <- nb2listw(nyadjlw$neighbours, style="B")
```


```{r, echo = F, eval = F}
# 3. Summarize the results from SAR
SAR <- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
                               data=nydata, listw=listw_NY, family="SAR", method="eigen")
summary(SAR)

# 4. Choose a model between lm0, SAR, and CAR
CAR <- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
                data=nydata, listw=listw_NY, family="CAR", method="eigen")
summary(CAR)
```

# Bayesian Models for Areal Data

## `CARBayes`

Similar to earlier functionality, there are R packages for analyzing areal data using Bayesian methods. We will look at `CARBayes` [Tutorial](https://cran.r-project.org/web/packages/CARBayes/vignettes/CARBayes.pdf)

## Property Values in Glasgow Tutorial

- Using the `CARBayes` package, answer the following questions.

1. Describe the data set
2. What are the results of `moran.mc`? What is the purpose of using `resid.model` as the response?
3. Interpret and describe the results of the `S.CARleroux()` model call.

```{r, eval = F, echo = F}
# Data processing
data(GGHB.IG)
data(pricedata)
propertydata.spatial <- merge(x=GGHB.IG, y=pricedata, by="IG", all.x=FALSE)
summary(propertydata.spatial)
propertydata.spatial <- spTransform(propertydata.spatial, CRS("+proj=longlat +datum=WGS84 +no_defs"))


# Data Viz
library(leaflet)
colours <- colorNumeric(palette = "BuPu", domain = propertydata.spatial@data$price) 

map1 <- leaflet(data=propertydata.spatial) %>% addTiles() %>%
    addPolygons(fillColor = ~colours(price), color="red", weight=1,fillOpacity = 0.7) %>%
    addLegend(pal = colours, values = propertydata.spatial@data$price, opacity = 1, title = 'Price') %>%
addScaleBar(position="bottomleft")


## data transformation
propertydata.spatial@data$logprice <- log(propertydata.spatial@data$price)
propertydata.spatial@data$logdriveshop <- log(propertydata.spatial@data$driveshop)
form <- logprice~crime+rooms+sales+factor(type) + logdriveshop
model <- lm(formula=form, data=propertydata.spatial@data)

# Spatial assessment

W.nb <- poly2nb(propertydata.spatial, row.names = rownames(propertydata.spatial@data)) 
W.list <- nb2listw(W.nb, style="B")
resid.model <- residuals(model)
moran.mc(x=resid.model, listw=W.list, nsim=1000)

# Model fitting
W <- nb2mat(W.nb, style="B")
model.spatial <- S.CARleroux(formula=form, data=propertydata.spatial@data, 
                             family="gaussian", W=W, burnin=100000, n.sample=300000, thin=20)
print(model.spatial)
summary(model.spatial)
summarise.samples(model.spatial$samples$beta, quantiles=c(0.5, 0.025, 0.975))
```


## JAGS

- Again JAGS is a possibility for any situation, it just requires sampling model and prior along with explicit documentation.

- Recall
\begin{eqnarray*}
Y_i | \psi_i &\sim& Poisson(E_i \exp(\psi_i))\\
\psi_i &=& \boldsymbol{x_i^T}\boldsymbol{\beta} + \theta_i + \phi_i
\end{eqnarray*}
where $\boldsymbol{x_i}$ are spatial covariates, $\theta_i$ corresponds to region wide heterogeneity, and $\psi_i$ captures local clustering.

## JAGS model code
```{r, eval = F, echo = T}
car_model <- "model {
  for (i in 1 : regions) {
    O[i] ~ dpois(mu[i])
    log(mu[i]) <- log(E[i]) + beta0 + beta1*x1 + phi[i] + theta[i]
    theta[i] ~ dnorm(0.0, tau.h)
    xi[i] <- theta[i] + phi[i]
    SMRhat[i] <- 100 * mu[i] / E[i]
    SMRraw[i] <- 100 * O[i] / E[i]
  }
  phi[1:regions] ~ car.normal(adj[], weights[], num[], tau.c)
  
  beta0 ~ dnorm(0.0, 1.0E-5)
  beta1 ~ dnorm(0.0, 1.0E-5)
  
  tau.h ~ dgamma(1.0E-3, 1.0E-3)
  tau.c ~ dgamma(1.0E-3, 1.0E-3)
  
  sd.h <- sd(theta[]) #marginal SD of heterogeneity effects
  sd.c <- sd(phi[]) # marginal SD of clustering effects
  alpha <- sd.c / (sd.h + sd.c)
  }
}"
```